{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring precision and recall\n",
    "\n",
    "The goal of this second notebook is to understand precision-recall in the context of classifiers.\n",
    "\n",
    " * Use Amazon review data in its entirety.\n",
    " * Train a logistic regression model.\n",
    " * Explore various evaluation metrics: accuracy, confusion matrix, precision, recall.\n",
    " * Explore how various metrics can be combined to produce a cost of making an error.\n",
    " * Explore precision and recall curves.\n",
    " \n",
    "Because we are using the full Amazon review dataset (not a subset of words or reviews), in this assignment we return to using Turi Create for its efficiency. As usual, let's start by **firing up Turi Create**.\n",
    "\n",
    "Make sure you have the latest version of Turi Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import turicreate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load amazon review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = turicreate.SFrame('amazon_baby.sframe/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract word counts and sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the first assignment of this course, we compute the word counts for individual words and extract positive and negative sentiments from ratings. To summarize, we perform the following:\n",
    "\n",
    "1. Remove punctuation.\n",
    "2. Remove reviews with \"neutral\" sentiment (rating 3).\n",
    "3. Set reviews with rating 4 or more to be positive and those with 2 or less to be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    try: # python 2.x\n",
    "        text = text.translate(None, string.punctuation) \n",
    "    except: # python 3.x\n",
    "        translator = text.maketrans('', '', string.punctuation)\n",
    "        text = text.translate(translator)\n",
    "    return text\n",
    "\n",
    "# Remove punctuation.\n",
    "review_clean = products['review'].apply(remove_punctuation)\n",
    "\n",
    "# Count words\n",
    "products['word_count'] = turicreate.text_analytics.count_words(review_clean)\n",
    "\n",
    "# Drop neutral sentiment reviews.\n",
    "products = products[products['rating'] != 3]\n",
    "\n",
    "# Positive sentiment to +1 and negative sentiment to -1\n",
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's remember what the dataset looks like by taking a quick peek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">review</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">rating</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">word_count</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Planetwise Wipe Pouch</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">it came early and was not<br>disappointed. i love ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;recommend&#x27;: 1.0,<br>&#x27;disappointed&#x27;: 1.0, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Annas Dream Full Quilt<br>with 2 Shams ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Very soft and comfortable<br>and warmer than it ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;quilt&#x27;: 1.0, &#x27;this&#x27;:<br>1.0, &#x27;for&#x27;: 1.0, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Stop Pacifier Sucking<br>without tears with ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">This is a product well<br>worth the purchase.  I ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;tool&#x27;: 1.0, &#x27;clever&#x27;:<br>1.0, &#x27;binky&#x27;: 2.0, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Stop Pacifier Sucking<br>without tears with ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">All of my kids have cried<br>non-stop when I tried to ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;rock&#x27;: 1.0,<br>&#x27;headachesthanks&#x27;: 1.0, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Stop Pacifier Sucking<br>without tears with ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">When the Binky Fairy came<br>to our house, we didn&#x27;t ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;thumb&#x27;: 1.0, &#x27;or&#x27;: 1.0,<br>&#x27;break&#x27;: 1.0, &#x27;trying&#x27;: ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A Tale of Baby&#x27;s Days<br>with Peter Rabbit ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Lovely book, it&#x27;s bound<br>tightly so you may no ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;2995&#x27;: 1.0, &#x27;for&#x27;: 1.0,<br>&#x27;barnes&#x27;: 1.0, &#x27;at&#x27;:  ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Baby Tracker&amp;reg; - Daily<br>Childcare Journal, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Perfect for new parents.<br>We were able to keep ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;right&#x27;: 1.0, &#x27;because&#x27;:<br>1.0, &#x27;questions&#x27;: 1.0, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Baby Tracker&amp;reg; - Daily<br>Childcare Journal, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A friend of mine pinned<br>this product on Pinte ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;like&#x27;: 1.0, &#x27;and&#x27;: 1.0,<br>&#x27;changes&#x27;: 1.0, &#x27;the&#x27;: ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Baby Tracker&amp;reg; - Daily<br>Childcare Journal, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">This has been an easy way<br>for my nanny to record ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;in&#x27;: 1.0, &#x27;pages&#x27;: 1.0,<br>&#x27;out&#x27;: 1.0, &#x27;run&#x27;: 1.0, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Baby Tracker&amp;reg; - Daily<br>Childcare Journal, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">I love this journal and<br>our nanny uses it ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{&#x27;tracker&#x27;: 1.0, &#x27;now&#x27;:<br>1.0, &#x27;postits&#x27;: 1.0, ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n</table>\n[166752 rows x 5 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n</div>",
      "text/plain": "Columns:\n\tname\tstr\n\treview\tstr\n\trating\tfloat\n\tword_count\tdict\n\tsentiment\tint\n\nRows: 166752\n\nData:\n+-------------------------------+-------------------------------+--------+\n|              name             |             review            | rating |\n+-------------------------------+-------------------------------+--------+\n|     Planetwise Wipe Pouch     | it came early and was not ... |  5.0   |\n| Annas Dream Full Quilt wit... | Very soft and comfortable ... |  5.0   |\n| Stop Pacifier Sucking with... | This is a product well wor... |  5.0   |\n| Stop Pacifier Sucking with... | All of my kids have cried ... |  5.0   |\n| Stop Pacifier Sucking with... | When the Binky Fairy came ... |  5.0   |\n| A Tale of Baby's Days with... | Lovely book, it's bound ti... |  4.0   |\n| Baby Tracker&reg; - Daily ... | Perfect for new parents. W... |  5.0   |\n| Baby Tracker&reg; - Daily ... | A friend of mine pinned th... |  5.0   |\n| Baby Tracker&reg; - Daily ... | This has been an easy way ... |  4.0   |\n| Baby Tracker&reg; - Daily ... | I love this journal and ou... |  4.0   |\n+-------------------------------+-------------------------------+--------+\n+-------------------------------+-----------+\n|           word_count          | sentiment |\n+-------------------------------+-----------+\n| {'recommend': 1.0, 'disapp... |     1     |\n| {'quilt': 1.0, 'this': 1.0... |     1     |\n| {'tool': 1.0, 'clever': 1.... |     1     |\n| {'rock': 1.0, 'headachesth... |     1     |\n| {'thumb': 1.0, 'or': 1.0, ... |     1     |\n| {'2995': 1.0, 'for': 1.0, ... |     1     |\n| {'right': 1.0, 'because': ... |     1     |\n| {'like': 1.0, 'and': 1.0, ... |     1     |\n| {'in': 1.0, 'pages': 1.0, ... |     1     |\n| {'tracker': 1.0, 'now': 1.... |     1     |\n+-------------------------------+-----------+\n[166752 rows x 5 columns]\nNote: Only the head of the SFrame is printed.\nYou can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n",
    "\n",
    "We split the data into a 80-20 split where 80% is in the training set and 20% is in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = products.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression classifier\n",
    "\n",
    "We will now train a logistic regression classifier with **sentiment** as the target and **word_count** as the features. We will set `validation_set=None` to make sure everyone gets exactly the same results.  \n",
    "\n",
    "Remember, even though we now know how to implement logistic regression, we will use Turi Create for its efficiency at processing this Amazon dataset in its entirety.  The focus of this assignment is instead on the topic of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>Logistic regression:</pre>",
      "text/plain": "Logistic regression:"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>--------------------------------------------------------</pre>",
      "text/plain": "--------------------------------------------------------"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>Number of examples          : 133416</pre>",
      "text/plain": "Number of examples          : 133416"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>Number of classes           : 2</pre>",
      "text/plain": "Number of classes           : 2"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>Number of feature columns   : 1</pre>",
      "text/plain": "Number of feature columns   : 1"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>Number of unpacked features : 121712</pre>",
      "text/plain": "Number of unpacked features : 121712"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>Number of coefficients      : 121713</pre>",
      "text/plain": "Number of coefficients      : 121713"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>Starting L-BFGS</pre>",
      "text/plain": "Starting L-BFGS"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>--------------------------------------------------------</pre>",
      "text/plain": "--------------------------------------------------------"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>+-----------+----------+-----------+--------------+-------------------+</pre>",
      "text/plain": "+-----------+----------+-----------+--------------+-------------------+"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy |</pre>",
      "text/plain": "| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy |"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>+-----------+----------+-----------+--------------+-------------------+</pre>",
      "text/plain": "+-----------+----------+-----------+--------------+-------------------+"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>| 0         | 4        | 0.250000  | 2.441376     | 0.840754          |</pre>",
      "text/plain": "| 0         | 4        | 0.250000  | 2.441376     | 0.840754          |"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>| 1         | 9        | 3.250000  | 4.174408     | 0.941514          |</pre>",
      "text/plain": "| 1         | 9        | 3.250000  | 4.174408     | 0.941514          |"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>| 2         | 11       | 2.778177  | 4.999917     | 0.942638          |</pre>",
      "text/plain": "| 2         | 11       | 2.778177  | 4.999917     | 0.942638          |"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>| 3         | 12       | 2.778177  | 5.558164     | 0.967822          |</pre>",
      "text/plain": "| 3         | 12       | 2.778177  | 5.558164     | 0.967822          |"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>| 4         | 13       | 2.778177  | 6.133470     | 0.976495          |</pre>",
      "text/plain": "| 4         | 13       | 2.778177  | 6.133470     | 0.976495          |"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>| 5         | 14       | 2.778177  | 6.671927     | 0.976495          |</pre>",
      "text/plain": "| 5         | 14       | 2.778177  | 6.671927     | 0.976495          |"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<pre>+-----------+----------+-----------+--------------+-------------------+</pre>",
      "text/plain": "+-----------+----------+-----------+--------------+-------------------+"
     },
     "metadata": {}
    }
   ],
   "source": [
    "model = turicreate.logistic_classifier.create(train_data, target='sentiment',\n",
    "                                              features=['word_count'],\n",
    "                                              validation_set=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore the advanced model evaluation concepts that were discussed in the lectures.\n",
    "\n",
    "## Accuracy\n",
    "\n",
    "One performance metric we will use for our more advanced exploration is accuracy, which we have seen many times in past assignments.  Recall that the accuracy is given by\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "To obtain the accuracy of our trained models using Turi Create, simply pass the option `metric='accuracy'` to the `evaluate` function. We compute the **accuracy** of our logistic regression model on the **test_data** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test Accuracy: 0.9221862251019919\n"
    }
   ],
   "source": [
    "accuracy= model.evaluate(test_data, metric='accuracy')['accuracy']\n",
    "print(\"Test Accuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "Recall from an earlier assignment that we used the **majority class classifier** as a baseline (i.e reference) model for a point of comparison with a more sophisticated classifier. The majority classifier model predicts the majority class for all data points. \n",
    "\n",
    "Typically, a good model should beat the majority class classifier. Since the majority class in this dataset is the positive class (i.e., there are more positive than negative reviews), the accuracy of the majority class classifier can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Baseline accuracy (majority class classifier): 0.8427825773938085\n"
    }
   ],
   "source": [
    "baseline = len(test_data[test_data['sentiment'] == 1])/len(test_data)\n",
    "print(\"Baseline accuracy (majority class classifier): %s\" % baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Using accuracy as the evaluation metric, was our **logistic regression model** better than the baseline (majority class classifier)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "The accuracy, while convenient, does not tell the whole story. For a fuller picture, we turn to the **confusion matrix**. In the case of binary classification, the confusion matrix is a 2-by-2 matrix laying out correct and incorrect predictions made in each label as follows:\n",
    "```\n",
    "              +---------------------------------------------+\n",
    "              |                Predicted label              |\n",
    "              +----------------------+----------------------+\n",
    "              |          (+1)        |         (-1)         |\n",
    "+-------+-----+----------------------+----------------------+\n",
    "| True  |(+1) | # of true positives  | # of false negatives |\n",
    "| label +-----+----------------------+----------------------+\n",
    "|       |(-1) | # of false positives | # of true negatives  |\n",
    "+-------+-----+----------------------+----------------------+\n",
    "```\n",
    "To print out the confusion matrix for a classifier, use `metric='confusion_matrix'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">target_label</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">predicted_label</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">896</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3543</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1698</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">27199</td>\n    </tr>\n</table>\n[4 rows x 3 columns]<br/>\n</div>",
      "text/plain": "Columns:\n\ttarget_label\tint\n\tpredicted_label\tint\n\tcount\tint\n\nRows: 4\n\nData:\n+--------------+-----------------+-------+\n| target_label | predicted_label | count |\n+--------------+-----------------+-------+\n|      1       |        -1       |  896  |\n|      -1      |        -1       |  3543 |\n|      -1      |        1        |  1698 |\n|      1       |        1        | 27199 |\n+--------------+-----------------+-------+\n[4 rows x 3 columns]"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "confusion_matrix = model.evaluate(test_data, metric='confusion_matrix')['confusion_matrix']\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: How many predicted values in the **test set** are **false positives**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the cost of mistakes\n",
    "\n",
    "\n",
    "Put yourself in the shoes of a manufacturer that sells a baby product on Amazon.com and you want to monitor your product's reviews in order to respond to complaints.  Even a few negative reviews may generate a lot of bad publicity about the product. So you don't want to miss any reviews with negative sentiments --- you'd rather put up with false alarms about potentially negative reviews instead of missing negative reviews entirely. In other words, **false positives cost more than false negatives**. (It may be the other way around for other scenarios, but let's stick with the manufacturer's scenario for now.)\n",
    "\n",
    "Suppose you know the costs involved in each kind of mistake: \n",
    "1. \\$100 for each false positive.\n",
    "2. \\$1 for each false negative.\n",
    "3. Correctly classified reviews incur no cost.\n",
    "\n",
    "**Quiz Question**: Given the stipulation, what is the cost associated with the logistic regression classifier's performance on the **test set**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=confusion_matrix[2]['count']\n",
    "fn=confusion_matrix[0]['count']\n",
    "pos=confusion_matrix[3]['count']\n",
    "neg=confusion_matrix[1]['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1698\n896\n"
    }
   ],
   "source": [
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "170696"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "100*fp+fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3543"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may not have exact dollar amounts for each kind of mistake. Instead, you may simply prefer to reduce the percentage of false positives to be less than, say, 3.5% of all positive predictions. This is where **precision** comes in:\n",
    "\n",
    "$$\n",
    "[\\text{precision}] = \\frac{[\\text{# positive data points with positive predicitions}]}{\\text{[# all data points with positive predictions]}} = \\frac{[\\text{# true positives}]}{[\\text{# true positives}] + [\\text{# false positives}]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to keep the percentage of false positives below 3.5% of positive predictions, we must raise the precision to 96.5% or higher. \n",
    "\n",
    "**First**, let us compute the precision of the logistic regression classifier on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision on test data: 0.941239575042392\n"
    }
   ],
   "source": [
    "precision = model.evaluate(test_data, metric='precision')['precision']\n",
    "print(\"Precision on test data: %s\" % precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Out of all reviews in the **test set** that are predicted to be positive, what fraction of them are **false positives**? (Round to the second decimal place e.g. 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.058760424957608054"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "fp/(pos+fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Based on what we learned in lecture, if we wanted to reduce this fraction of false positives to be below 3.5%, we would (select one):\n",
    "\n",
    "- Discard a sufficient number of positive predictions\n",
    "- Discard a sufficient number of negative predictins\n",
    "- Increase threshold for predicting the positive class ($y_{hat} = +1$)\n",
    "- Decrease threshold for predicting the positive class ($y_{hat} = +1$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complementary metric is **recall**, which measures the ratio between the number of true positives and that of (ground-truth) positive reviews:\n",
    "\n",
    "$$\n",
    "[\\text{recall}] = \\frac{[\\text{# positive data points with positive predicitions}]}{\\text{[# all positive data points]}} = \\frac{[\\text{# true positives}]}{[\\text{# true positives}] + [\\text{# false negatives}]}\n",
    "$$\n",
    "\n",
    "Let us compute the recall on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Recall on test data: 0.9681082043068162\n"
    }
   ],
   "source": [
    "recall = model.evaluate(test_data, metric='recall')['recall']\n",
    "print(\"Recall on test data: %s\" % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9681082043068162"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "pos/(pos+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What fraction of the positive reviews in the **test_set** were correctly predicted as positive by the classifier?\n",
    "\n",
    "**Quiz Question**: What is the recall value for a classifier that predicts **+1** for all data points in the **test_data**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Precision-recall tradeoff\n",
    "\n",
    "In this part, we will explore the trade-off between precision and recall discussed in the lecture.  We first examine what happens when we use a different threshold value for making class predictions.  We then explore a range of threshold values and plot the associated precision-recall curve.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying the threshold\n",
    "\n",
    "False positives are costly in our example, so we may want to be more conservative about making positive predictions. To achieve this, instead of thresholding class probabilities at 0.5, we can choose a higher threshold. \n",
    "\n",
    "Write a function called `apply_threshold` that accepts two things\n",
    "* `probabilities` (an SArray of probability values)\n",
    "* `threshold` (a float between 0 and 1).\n",
    "\n",
    "The function should return an SArray, where each element is set to +1 or -1 depending whether the corresponding probability exceeds `threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(probabilities, threshold):\n",
    "    ### YOUR CODE GOES HERE\n",
    "    # +1 if >= threshold and -1 otherwise.\n",
    "    return(probabilities.apply(lambda x:1 if x>threshold else -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run prediction with `output_type='probability'` to get the list of probability values. Then use thresholds set at 0.5 (default) and 0.9 to make predictions from these probability values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(test_data, output_type='probability')\n",
    "predictions_with_default_threshold = apply_threshold(probabilities, 0.5)\n",
    "predictions_with_high_threshold = apply_threshold(probabilities, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of positive predicted reviews (threshold = 0.5): 28897\n"
    }
   ],
   "source": [
    "print(\"Number of positive predicted reviews (threshold = 0.5): %s\" % (predictions_with_default_threshold == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of positive predicted reviews (threshold = 0.9): 25031\n"
    }
   ],
   "source": [
    "print(\"Number of positive predicted reviews (threshold = 0.9): %s\" % (predictions_with_high_threshold == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What happens to the number of positive predicted reviews as the threshold increased from 0.5 to 0.9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the associated precision and recall as the threshold varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the probability threshold, it is possible to influence precision and recall. We can explore this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Threshold = 0.5\n",
    "precision_with_default_threshold = turicreate.evaluation.precision(test_data['sentiment'],\n",
    "                                        predictions_with_default_threshold)\n",
    "\n",
    "recall_with_default_threshold = turicreate.evaluation.recall(test_data['sentiment'],\n",
    "                                        predictions_with_default_threshold)\n",
    "\n",
    "# Threshold = 0.9\n",
    "precision_with_high_threshold = turicreate.evaluation.precision(test_data['sentiment'],\n",
    "                                        predictions_with_high_threshold)\n",
    "recall_with_high_threshold = turicreate.evaluation.recall(test_data['sentiment'],\n",
    "                                        predictions_with_high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision (threshold = 0.5): 0.941239575042392\nRecall (threshold = 0.5)   : 0.9681082043068162\n"
    }
   ],
   "source": [
    "print(\"Precision (threshold = 0.5): %s\" % precision_with_default_threshold)\n",
    "print(\"Recall (threshold = 0.5)   : %s\" % recall_with_default_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision (threshold = 0.9): 0.9728736366905038\nRecall (threshold = 0.9)   : 0.8667734472326036\n"
    }
   ],
   "source": [
    "print(\"Precision (threshold = 0.9): %s\" % precision_with_high_threshold)\n",
    "print(\"Recall (threshold = 0.9)   : %s\" % recall_with_high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question (variant 1)**: Does the **precision** increase with a higher threshold?\n",
    "\n",
    "**Quiz Question (variant 2)**: Does the **recall** increase with a higher threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-recall curve\n",
    "\n",
    "Now, we will explore various different values of tresholds, compute the precision and recall scores, and then plot the precision-recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.5        0.50505051 0.51010101 0.51515152 0.52020202 0.52525253\n 0.53030303 0.53535354 0.54040404 0.54545455 0.55050505 0.55555556\n 0.56060606 0.56565657 0.57070707 0.57575758 0.58080808 0.58585859\n 0.59090909 0.5959596  0.6010101  0.60606061 0.61111111 0.61616162\n 0.62121212 0.62626263 0.63131313 0.63636364 0.64141414 0.64646465\n 0.65151515 0.65656566 0.66161616 0.66666667 0.67171717 0.67676768\n 0.68181818 0.68686869 0.69191919 0.6969697  0.7020202  0.70707071\n 0.71212121 0.71717172 0.72222222 0.72727273 0.73232323 0.73737374\n 0.74242424 0.74747475 0.75252525 0.75757576 0.76262626 0.76767677\n 0.77272727 0.77777778 0.78282828 0.78787879 0.79292929 0.7979798\n 0.8030303  0.80808081 0.81313131 0.81818182 0.82323232 0.82828283\n 0.83333333 0.83838384 0.84343434 0.84848485 0.85353535 0.85858586\n 0.86363636 0.86868687 0.87373737 0.87878788 0.88383838 0.88888889\n 0.89393939 0.8989899  0.9040404  0.90909091 0.91414141 0.91919192\n 0.92424242 0.92929293 0.93434343 0.93939394 0.94444444 0.94949495\n 0.95454545 0.95959596 0.96464646 0.96969697 0.97474747 0.97979798\n 0.98484848 0.98989899 0.99494949 1.        ]\n"
    }
   ],
   "source": [
    "threshold_values = np.linspace(0.5, 1, num=100)\n",
    "print(threshold_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the values of threshold, we compute the precision and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_all = []\n",
    "recall_all = []\n",
    "\n",
    "probabilities = model.predict(test_data, output_type='probability')\n",
    "for threshold in threshold_values:\n",
    "    predictions = apply_threshold(probabilities, threshold)\n",
    "    \n",
    "    precision = turicreate.evaluation.precision(test_data['sentiment'], predictions)\n",
    "    recall = turicreate.evaluation.recall(test_data['sentiment'], predictions)\n",
    "    \n",
    "    precision_all.append(precision)\n",
    "    recall_all.append(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the precision-recall curve to visualize the precision-recall tradeoff as we vary the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 504x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"331.674375pt\" version=\"1.1\" viewBox=\"0 0 441.58125 331.674375\" width=\"441.58125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 331.674375 \nL 441.58125 331.674375 \nL 441.58125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 294.118125 \nL 434.38125 294.118125 \nL 434.38125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2f504b8770\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.962395\" xlink:href=\"#m2f504b8770\" y=\"294.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.94 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(40.829583 308.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"206.42501\" xlink:href=\"#m2f504b8770\" y=\"294.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.96 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(195.292197 308.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"360.887624\" xlink:href=\"#m2f504b8770\" y=\"294.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.98 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(349.754812 308.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_4\">\n     <!-- Precision -->\n     <defs>\n      <path d=\"M 19.671875 64.796875 \nL 19.671875 37.40625 \nL 32.078125 37.40625 \nQ 38.96875 37.40625 42.71875 40.96875 \nQ 46.484375 44.53125 46.484375 51.125 \nQ 46.484375 57.671875 42.71875 61.234375 \nQ 38.96875 64.796875 32.078125 64.796875 \nz\nM 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.34375 72.90625 50.609375 67.359375 \nQ 56.890625 61.8125 56.890625 51.125 \nQ 56.890625 40.328125 50.609375 34.8125 \nQ 44.34375 29.296875 32.078125 29.296875 \nL 19.671875 29.296875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-80\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(216.576563 322.394687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.287109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"101.369141\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"162.892578\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"217.873047\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"245.65625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"297.755859\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"325.539062\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"386.720703\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_4\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3fc4563acb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3fc4563acb\" y=\"270.819469\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(20.878125 274.618687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3fc4563acb\" y=\"220.372415\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 224.171634)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3fc4563acb\" y=\"169.925361\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(20.878125 173.72458)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3fc4563acb\" y=\"119.478307\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 123.277526)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3fc4563acb\" y=\"69.031253\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.9 -->\n      <g transform=\"translate(20.878125 72.830472)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Recall -->\n     <defs>\n      <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(14.798438 173.357188)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.419922\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"130.943359\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"185.923828\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"247.203125\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"274.986328\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_9\">\n    <path clip-path=\"url(#pfd0612151e)\" d=\"M 61.535795 34.67267 \nL 64.872176 34.888141 \nL 67.6946 35.121568 \nL 68.991542 35.37295 \nL 72.611043 35.570465 \nL 76.221824 35.785935 \nL 78.810275 36.019362 \nL 80.433578 36.198921 \nL 82.028622 36.414391 \nL 85.86856 36.683729 \nL 86.931097 36.935112 \nL 90.528149 37.20445 \nL 93.11175 37.473788 \nL 96.810215 37.635391 \nL 98.139487 37.886774 \nL 101.006995 38.138156 \nL 104.165038 38.353627 \nL 107.028846 38.622965 \nL 109.426634 38.838435 \nL 112.099681 39.03595 \nL 115.507727 39.287332 \nL 117.604109 39.574627 \nL 119.229426 39.808053 \nL 121.821859 40.131259 \nL 123.383761 40.454465 \nL 125.971636 40.795627 \nL 129.658392 41.064965 \nL 133.325914 41.370215 \nL 134.451259 41.603641 \nL 138.103953 41.944803 \nL 141.149991 42.411656 \nL 144.85984 42.69895 \nL 148.551747 43.022156 \nL 150.991862 43.273539 \nL 153.724703 43.489009 \nL 157.04644 43.991774 \nL 159.612461 44.458627 \nL 167.905405 47.349524 \nL 170.303835 47.726598 \nL 174.01644 48.139583 \nL 177.15582 48.624392 \nL 179.209049 49.145112 \nL 180.9634 49.719701 \nL 184.95643 50.168598 \nL 189.840307 50.509759 \nL 192.755553 50.994568 \nL 194.833407 51.533245 \nL 197.586319 51.874407 \nL 201.7995 52.484907 \nL 203.910844 53.005627 \nL 206.379656 53.400657 \nL 208.741608 53.975245 \nL 211.122065 54.531877 \nL 215.973173 55.08851 \nL 217.758051 55.752877 \nL 222.088502 56.30951 \nL 227.060487 56.740451 \nL 230.519457 57.422775 \nL 234.185042 58.248745 \nL 237.332514 59.038804 \nL 240.266385 59.739083 \nL 243.987614 60.547098 \nL 248.275429 61.373069 \nL 250.469127 62.468378 \nL 253.519546 63.563687 \nL 256.850085 64.694907 \nL 259.79793 65.520878 \nL 263.419551 66.705966 \nL 266.835115 67.783319 \nL 270.110442 69.165922 \nL 272.97334 70.279187 \nL 275.434901 71.643834 \nL 278.437057 73.116216 \nL 281.088739 74.750202 \nL 286.287082 76.007114 \nL 290.777363 77.587231 \nL 292.354371 79.777849 \nL 298.123839 81.304099 \nL 301.636482 83.297202 \nL 305.71712 85.433952 \nL 309.313334 87.409099 \nL 314.482092 90.012703 \nL 318.996795 92.867688 \nL 323.498744 95.902232 \nL 328.670151 98.990644 \nL 335.802412 102.097012 \nL 340.614365 105.742056 \nL 346.058163 109.638483 \nL 352.038238 114.109498 \nL 357.336527 119.873336 \nL 365.549612 126.35541 \nL 372.400496 133.627543 \nL 379.831625 142.030896 \nL 387.801509 152.014367 \nL 392.905724 164.152544 \nL 396.606406 180.384663 \nL 402.318449 201.482826 \nL 409.579686 232.097607 \nL 416.626705 281.76358 \n\" style=\"fill:none;stroke:#b0017f;stroke-linecap:square;stroke-width:4;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 294.118125 \nL 43.78125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 434.38125 294.118125 \nL 434.38125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 294.118125 \nL 434.38125 294.118125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 434.38125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_11\">\n    <!-- Precision recall curve (all) -->\n    <defs>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n     <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n     <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n    </defs>\n    <g transform=\"translate(161.385 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-80\"/>\n     <use x=\"60.287109\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"101.369141\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"162.892578\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"217.873047\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"245.65625\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"297.755859\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"325.539062\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"386.720703\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"450.099609\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"481.886719\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"522.96875\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"584.492188\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"639.472656\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"700.751953\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"728.535156\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"756.318359\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"788.105469\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"843.085938\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"906.464844\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"947.578125\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"1006.757812\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1068.28125\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1100.068359\" xlink:href=\"#DejaVuSans-40\"/>\n     <use x=\"1139.082031\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"1200.361328\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"1228.144531\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"1255.927734\" xlink:href=\"#DejaVuSans-41\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfd0612151e\">\n   <rect height=\"271.8\" width=\"390.6\" x=\"43.78125\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_pr_curve(precision, recall, title):\n",
    "    plt.rcParams['figure.figsize'] = 7, 5\n",
    "    plt.locator_params(axis = 'x', nbins = 5)\n",
    "    plt.plot(precision, recall, 'b-', linewidth=4.0, color = '#B0017F')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    \n",
    "plot_pr_curve(precision_all, recall_all, 'Precision recall curve (all)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Among all the threshold values tried, what is the **smallest** threshold value that achieves a precision of 96.5% or better? Round your answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "62\n"
    }
   ],
   "source": [
    "for x in range(len(precision_all)):\n",
    "    if(precision_all[x]>0.965):\n",
    "        print(x)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8131313131313131\n"
    }
   ],
   "source": [
    "print(threshold_values[62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Using `threshold` = 0.98, how many **false negatives** do we get on the **test_data**? (**Hint**: You may use the `turicreate.evaluation.confusion_matrix` function implemented in Turi Create.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">target_label</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">predicted_label</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">count</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9056</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">19039</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4943</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">298</td>\n    </tr>\n</table>\n[4 rows x 3 columns]<br/>\n</div>",
      "text/plain": "Columns:\n\ttarget_label\tint\n\tpredicted_label\tint\n\tcount\tint\n\nRows: 4\n\nData:\n+--------------+-----------------+-------+\n| target_label | predicted_label | count |\n+--------------+-----------------+-------+\n|      1       |        -1       |  9056 |\n|      1       |        1        | 19039 |\n|      -1      |        -1       |  4943 |\n|      -1      |        1        |  298  |\n+--------------+-----------------+-------+\n[4 rows x 3 columns]"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "prediction=apply_threshold(probabilities,0.98)\n",
    "turicreate.evaluation.confusion_matrix(test_data['sentiment'],prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of false negatives (i.e the number of reviews to look at when not needed) that we have to deal with using this classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating specific search terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we looked at the number of false positives for the **entire test set**. In this section, let's select reviews using a specific search term and optimize the precision on these reviews only. After all, a manufacturer would be interested in tuning the false positive rate just for their products (the reviews they want to read) rather than that of the entire set of products on Amazon.\n",
    "\n",
    "## Precision-Recall on all baby related items\n",
    "\n",
    "From the **test set**, select all the reviews for all products with the word 'baby' in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_reviews =  test_data[test_data['name'].apply(lambda x: 'baby' in x.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's predict the probability of classifying these reviews as positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(baby_reviews, output_type='probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the precision-recall curve for the **baby_reviews** dataset.\n",
    "\n",
    "**First**, let's consider the following `threshold_values` ranging from 0.5 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_values = np.linspace(0.5, 1, num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second**, as we did above, let's compute precision and recall for each value in `threshold_values` on the **baby_reviews** dataset.  Complete the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_all = []\n",
    "recall_all = []\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    \n",
    "    # Make predictions. Use the `apply_threshold` function \n",
    "    ## YOUR CODE HERE \n",
    "    predictions = apply_threshold(probabilities,threshold)\n",
    "\n",
    "    # Calculate the precision.\n",
    "    # YOUR CODE HERE\n",
    "    precision = turicreate.evaluation.precision(baby_reviews['sentiment'],predictions)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    recall = turicreate.evaluation.recall(baby_reviews['sentiment'],predictions)\n",
    "    \n",
    "    # Append the precision and recall scores.\n",
    "    precision_all.append(precision)\n",
    "    recall_all.append(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Among all the threshold values tried, what is the **smallest** threshold value that achieves a precision of 96.5% or better for the reviews of data in **baby_reviews**? Round your answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "69\n"
    }
   ],
   "source": [
    "for x in range(len(precision_all)):\n",
    "    if(precision_all[x]>0.965):\n",
    "        print(x)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8484848484848485\n"
    }
   ],
   "source": [
    "print(threshold_values[69])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Is this threshold value smaller or larger than the threshold used for the entire dataset to achieve the same specified precision of 96.5%?\n",
    "\n",
    "**Finally**, let's plot the precision recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 504x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"331.674375pt\" version=\"1.1\" viewBox=\"0 0 441.58125 331.674375\" width=\"441.58125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 331.674375 \nL 441.58125 331.674375 \nL 441.58125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 294.118125 \nL 434.38125 294.118125 \nL 434.38125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m14c2909113\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"75.318543\" xlink:href=\"#m14c2909113\" y=\"294.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.94 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(64.18573 308.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.338448\" xlink:href=\"#m14c2909113\" y=\"294.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.96 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(214.205635 308.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"375.358352\" xlink:href=\"#m14c2909113\" y=\"294.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.98 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(364.22554 308.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_4\">\n     <!-- Precision -->\n     <defs>\n      <path d=\"M 19.671875 64.796875 \nL 19.671875 37.40625 \nL 32.078125 37.40625 \nQ 38.96875 37.40625 42.71875 40.96875 \nQ 46.484375 44.53125 46.484375 51.125 \nQ 46.484375 57.671875 42.71875 61.234375 \nQ 38.96875 64.796875 32.078125 64.796875 \nz\nM 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.34375 72.90625 50.609375 67.359375 \nQ 56.890625 61.8125 56.890625 51.125 \nQ 56.890625 40.328125 50.609375 34.8125 \nQ 44.34375 29.296875 32.078125 29.296875 \nL 19.671875 29.296875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-80\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(216.576563 322.394687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"60.287109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"101.369141\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"162.892578\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"217.873047\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"245.65625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"297.755859\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"325.539062\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"386.720703\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_4\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m134402809f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m134402809f\" y=\"266.586562\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(20.878125 270.385781)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m134402809f\" y=\"216.742517\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 220.541736)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m134402809f\" y=\"166.898473\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(20.878125 170.697692)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m134402809f\" y=\"117.054429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 120.853647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m134402809f\" y=\"67.210384\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.9 -->\n      <g transform=\"translate(20.878125 71.009603)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Recall -->\n     <defs>\n      <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(14.798438 173.357188)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.419922\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"130.943359\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"185.923828\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"247.203125\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"274.986328\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_9\">\n    <path clip-path=\"url(#p28621c9ab6)\" d=\"M 61.535795 34.67267 \nL 62.697568 34.76328 \nL 66.025274 35.216325 \nL 65.781241 35.488152 \nL 66.784715 35.759979 \nL 73.960294 36.122415 \nL 75.211995 36.122415 \nL 77.637202 36.213024 \nL 79.985829 36.394243 \nL 83.515039 36.66607 \nL 85.715433 37.028506 \nL 89.413834 37.119115 \nL 91.701873 37.390942 \nL 96.520212 37.662769 \nL 96.290221 37.934597 \nL 99.780353 38.297033 \nL 105.892594 38.56886 \nL 108.432135 38.56886 \nL 109.478826 38.840687 \nL 111.725385 39.203123 \nL 116.674507 39.384342 \nL 120.356916 39.56556 \nL 121.488904 39.746778 \nL 123.756554 40.109214 \nL 124.675389 40.562259 \nL 130.660425 41.105914 \nL 131.732108 41.377741 \nL 132.734239 41.740177 \nL 133.880137 41.921395 \nL 136.175674 42.283832 \nL 139.207318 43.37114 \nL 144.318958 43.461749 \nL 149.302835 43.733577 \nL 151.56086 44.186622 \nL 155.330986 44.36784 \nL 160.212676 44.820885 \nL 162.426875 45.36454 \nL 172.276211 48.082811 \nL 174.592343 48.535857 \nL 179.691081 48.807684 \nL 183.349559 49.260729 \nL 184.043964 50.16682 \nL 185.184421 50.438647 \nL 185.821282 51.435347 \nL 189.450126 51.979001 \nL 194.55507 52.341437 \nL 196.806021 52.975701 \nL 198.087641 53.06631 \nL 200.166189 53.9724 \nL 201.08711 54.606664 \nL 202.193326 54.9691 \nL 207.0599 55.784582 \nL 210.948321 56.056409 \nL 211.950398 56.600063 \nL 211.535026 57.234327 \nL 216.513747 57.959199 \nL 223.171683 58.231026 \nL 228.19597 58.955899 \nL 231.699108 59.952598 \nL 231.13715 60.858689 \nL 233.393208 61.674171 \nL 237.100193 62.399043 \nL 240.603529 63.486352 \nL 245.630995 64.392442 \nL 247.886471 65.298533 \nL 250.419355 65.751578 \nL 252.694332 66.657669 \nL 256.021676 68.198023 \nL 259.531353 69.46655 \nL 264.281668 71.097513 \nL 267.947651 72.184822 \nL 269.898815 73.815785 \nL 274.897796 75.174921 \nL 279.836696 76.715275 \nL 279.247161 77.802583 \nL 284.23716 79.342937 \nL 289.031003 81.336337 \nL 292.683149 82.786082 \nL 295.662192 85.594963 \nL 303.446202 87.860189 \nL 306.767193 90.216025 \nL 317.408199 93.206124 \nL 322.39349 95.561959 \nL 325.984713 97.736577 \nL 330.754391 100.817285 \nL 338.53792 104.351038 \nL 346.860413 106.978701 \nL 353.18663 110.874891 \nL 357.767523 115.405344 \nL 363.59539 121.204324 \nL 379.477892 127.546958 \nL 388.869244 134.523856 \nL 396.421319 142.859889 \nL 399.497784 154.820285 \nL 404.518231 167.233727 \nL 410.257975 184.449448 \nL 415.702008 204.383442 \nL 416.013509 234.103214 \nL 416.626705 281.76358 \n\" style=\"fill:none;stroke:#b0017f;stroke-linecap:square;stroke-width:4;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 294.118125 \nL 43.78125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 434.38125 294.118125 \nL 434.38125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 294.118125 \nL 434.38125 294.118125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 434.38125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_11\">\n    <!-- Precision-Recall (Baby) -->\n    <defs>\n     <path d=\"M 4.890625 31.390625 \nL 31.203125 31.390625 \nL 31.203125 23.390625 \nL 4.890625 23.390625 \nz\n\" id=\"DejaVuSans-45\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n     <path d=\"M 19.671875 34.8125 \nL 19.671875 8.109375 \nL 35.5 8.109375 \nQ 43.453125 8.109375 47.28125 11.40625 \nQ 51.125 14.703125 51.125 21.484375 \nQ 51.125 28.328125 47.28125 31.5625 \nQ 43.453125 34.8125 35.5 34.8125 \nz\nM 19.671875 64.796875 \nL 19.671875 42.828125 \nL 34.28125 42.828125 \nQ 41.5 42.828125 45.03125 45.53125 \nQ 48.578125 48.25 48.578125 53.8125 \nQ 48.578125 59.328125 45.03125 62.0625 \nQ 41.5 64.796875 34.28125 64.796875 \nz\nM 9.8125 72.90625 \nL 35.015625 72.90625 \nQ 46.296875 72.90625 52.390625 68.21875 \nQ 58.5 63.53125 58.5 54.890625 \nQ 58.5 48.1875 55.375 44.234375 \nQ 52.25 40.28125 46.1875 39.3125 \nQ 53.46875 37.75 57.5 32.78125 \nQ 61.53125 27.828125 61.53125 20.40625 \nQ 61.53125 10.640625 54.890625 5.3125 \nQ 48.25 0 35.984375 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-66\"/>\n     <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n    </defs>\n    <g transform=\"translate(170.001563 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-80\"/>\n     <use x=\"60.287109\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"101.369141\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"162.892578\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"217.873047\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"245.65625\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"297.755859\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"325.539062\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"386.720703\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"450.099609\" xlink:href=\"#DejaVuSans-45\"/>\n     <use x=\"486.183594\" xlink:href=\"#DejaVuSans-82\"/>\n     <use x=\"555.603516\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"617.126953\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"672.107422\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"733.386719\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"761.169922\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"788.953125\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"820.740234\" xlink:href=\"#DejaVuSans-40\"/>\n     <use x=\"859.753906\" xlink:href=\"#DejaVuSans-66\"/>\n     <use x=\"928.357422\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"989.636719\" xlink:href=\"#DejaVuSans-98\"/>\n     <use x=\"1053.113281\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"1112.292969\" xlink:href=\"#DejaVuSans-41\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p28621c9ab6\">\n   <rect height=\"271.8\" width=\"390.6\" x=\"43.78125\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plot_pr_curve(precision_all, recall_all, \"Precision-Recall (Baby)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit (conda)",
   "language": "python",
   "name": "python37664bitconda566ba5c91f704513ab58cb335e9679a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}